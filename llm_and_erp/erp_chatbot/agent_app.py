import streamlit as st
from sentence_transformers import SentenceTransformer, util
import requests
import json
import re

# === ğŸ“Œ MODEL & VERÄ°LER ===
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

embedding_model = load_embedding_model()

# Sekme embed JSON
sekme_descriptions_path = "<output_json_path>"  # Ã–rn: r"C:\Users\ebrars\Desktop\veri_hazÄ±rlama\output.json"
with open(sekme_descriptions_path, "r", encoding="utf-8") as f:
    structured_docs = json.load(f)

sekme_texts = [d["cumle"] for d in structured_docs]
sekme_embeddings = embedding_model.encode(sekme_texts, convert_to_tensor=True)

# AliaslÄ± kolon JSON
with open("sekme_columns_with_names_comment.json", "r", encoding="utf-8") as f:
    sekme_columns_data = json.load(f)

def clean_user_query(user_query: str) -> str:
    """
    KullanÄ±cÄ± sorgusunu basit kurallarla temizler.
    """
    # KÃ¼Ã§Ã¼k harfe Ã§evir
    q = user_query.lower()

    # Gereksiz baÄŸlaÃ§larÄ± sil
    q = re.sub(r'\b(lÃ¼tfen|acaba|rica ederim|acil|mÃ¼mkÃ¼nse)\b', '', q)

    # Fazla boÅŸluklarÄ± sil
    q = re.sub(r'\s+', ' ', q).strip()

    return q

def rewrite_query_with_llm(raw_query, model="mistral"):
    system_prompt = """
Sen bir sorgu dÃ¼zenleme asistanÄ±sÄ±n.
KullanÄ±cÄ±nÄ±n verdiÄŸi TÃ¼rkÃ§e soruyu daha net, kÄ±sa ve LLM iÃ§in anlaÅŸÄ±lÄ±r ÅŸekilde yeniden yaz.
AÃ§Ä±klama ekleme, sadece dÃ¼zenlenmiÅŸ soruyu dÃ¶ndÃ¼r.

"""
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": raw_query}
        ],
        "stream": False
    }

    response = requests.post("http://localhost:11434/api/chat", json=data)
    result = response.json()["message"]["content"]
    return result.strip()    
# === ğŸ” Sekme Bul ===
def find_best_matching_sekme(user_query):
    query_embedding = embedding_model.encode(user_query, convert_to_tensor=True)
    cos_scores = util.cos_sim(query_embedding, sekme_embeddings)[0]
    index = cos_scores.argmax().item()
    return structured_docs[index]["sekme"]

# === âš™ï¸ Ollama SQL ===
def ollama_sql_filter(prompt, sekme_name, model="mistral"):
    for sekme in sekme_columns_data:
        if sekme["sekme"] == sekme_name:
            alias_table_map = {}
            for col in sekme["columns"]:
                alias_table_map[col["alias"]] = col["table"]
            alias_table_map = {alias: table for alias, table in alias_table_map.items()}
            columns = [f"{col['alias']}.{col['column']}" for col in sekme["columns"]]
            break
    else:
        raise ValueError(f"Sekme bulunamadÄ±: {sekme_name}")

    from_clauses = [f"{table} AS {alias}" for alias, table in alias_table_map.items()]

    system_prompt = f"""
Sen bir SQL sorgu oluÅŸturma asistanÄ±sÄ±n.
KullanÄ±cÄ± TÃ¼rkÃ§e bir istek verecek. Sen SELECT * FROM ... WHERE ... formatÄ±nda TAM SQL sorgusu Ã¼ret.Olmayan tablolarÄ± asla ama asla kullanma.

Dikkat et:
- KullanabileceÄŸin tablolar ve aliaslar: {', '.join(from_clauses)}
- KullanabileceÄŸin kolonlar: {', '.join(columns)}
- AliaslarÄ± hem FROM kÄ±smÄ±nda hem WHERE kÄ±smÄ±nda doÄŸru kullan.
- SADECE Ã§alÄ±ÅŸtÄ±rÄ±labilir tam SQL dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama ekleme.
"""

    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "stream": False
    }

    response = requests.post("http://localhost:11434/api/chat", json=data)
    result = response.json()["message"]["content"]
    return result

# === ğŸ“Š Streamlit ArayÃ¼z ===
st.title("ğŸ” SQL Agent")

user_query = st.text_input("ğŸ’¬ Sorgunuzu girin:", placeholder="Ã–rn: 1234 ÅŸasi no lu araÃ§ stokta var mÄ±?")

if st.button("Sorguyu Ã‡alÄ±ÅŸtÄ±r"):
    if not user_query.strip():
        st.warning("LÃ¼tfen bir sorgu girin.")
    else:
        with st.spinner("â³ Ä°ÅŸleniyor..."):
            
            clean_query = clean_user_query(user_query)
            llm_refined_query = rewrite_query_with_llm(clean_query)
            best_sekme = find_best_matching_sekme(llm_refined_query)
            sql_result = ollama_sql_filter(llm_refined_query, best_sekme)

        st.success(f"ğŸ¯ En alakalÄ± sekme: **{best_sekme}**")
        st.code(sql_result, language="sql")
